# # ------------------------ #
# # 基础信息配置
# # ------------------------ #
# # 是否跳过节点物理资源校验
# skip_verify_node: false

# # 代理设置，若节点不能直接访问公网，可使用下面变量设置代理。
# http_proxy: 
# https_proxy: 
# no_proxy: 192.168.0.0/16,10.0.0.0/8,172.16.0.0/12,127.0.0.1,localhost

# # 是否禁用防护墙
# # 注意：本脚本不管理防火墙，您需要按照 "00-安装须知" 中所提及的 "端口占用" 手动进行放行相应端口。
# # 为了避免在部署过程中出现问题，您应该禁用防火墙。
# firewalld_disabled: true

# # 节点时区
# timezone: Asia/Shanghai

# # 是否启用 chrony 进行时间同步
# chrony_enabled: false
# ntp_server: "ntp.aliyun.com"
# chrony_image: "{{ kube_image_repository }}/setzero_chrony:3.5"

# # CentOS yum源仓库
# # 基础软件源
# # Kylin操作系统使用 https://update.cs2c.com.cn/NS/V10/V10SP2/os/adv/lic/base/$basearch/
# base_yum_repo: http://mirrors.aliyun.com/centos/$releasever/os/$basearch/
# # epel软件源（ CeontOS8默认使用：https://mirrors.aliyun.com/epel/$releasever/Everything/$basearch ）
# # Anolis 7+ 使用: http://mirrors.aliyun.com/epel/7/$basearch
# epel_yum_repo: http://mirrors.aliyun.com/epel/$releasever/$basearch
# # docker-ce源 (CentOS可使用：https://mirrors.aliyun.com/docker-ce/linux/centos/$releasever/$basearch/stable )
# docker_yum_repo: https://mirrors.aliyun.com/docker-ce/linux/centos/{{ ansible_distribution_major_version }}/$basearch/stable
# # kubernetes源
# kubernetes_yum_repo: https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-{{ ansible_architecture }}/

# # Debian apt源仓库
# # 基础软件源
# base_apt_repo: deb http://mirrors.aliyun.com/{{ host_distribution | lower }}/ {{ host_distribution_release }} main restricted universe multiverse
# # docker-ce源
# docker_apt_repo: "deb [arch={{ host_architecture }}] https://mirrors.aliyun.com/docker-ce/linux/{{ host_distribution | lower }} {{ host_distribution_release }} stable"
# # kubernetes源
# kubernetes_apt_repo: deb https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial main

# # 自定义hosts记录
# # 举例：
# # custom_hosts:
# #   "127.0.0.1": 
# #   - "one.domain.custom.local"
# #   - "tow.domain.custom.local"
# custom_hosts: {}

# # 是否nftables转换为iptables
# nftables_to_iptables: false
# # ------------------------ #
# # 容器运行时相关参数配置
# # ------------------------ #
# # 容器运行时类型，可选项：containerd，docker；默认 containerd
# container_manager: containerd
# # Docker版本
# docker_version: 20.10.24
# # containerd版本
# Containerd 版本
# containerd_version: 1.6.20-1
# # 数据存储目录
# containerd_storage_dir: "/var/lib/containerd"
# # 状态目录
# containerd_state_dir: "/run/containerd"
# # 应用于容器式守护进程的内存不足（OOM）分数（默认值：0）
# containerd_oom_score: -999
# containerd_grpc_max_recv_message_size: 16777216
# containerd_grpc_max_send_message_size: 16777216
# # 日志输出等级
# containerd_debug_level: "info"
# containerd_metrics_address: ""
# containerd_metrics_grpc_histogram: false
# containerd_max_container_log_line_size: -1
# containerd_default_runtime: "runc"
# containerd_snapshotter: "overlayfs"
# containerd_runtimes:
#   - name: runc
#     type: "io.containerd.runc.v2"
#     engine: ""
#     root: ""
#     options:
#       # containerd 是否使用 systemd 作为 cgroup 驱动程序
#       SystemdCgroup: "true"
# containerd_use_systemd_cgroup: "true"
# containerd_registries_config_dir: "/etc/containerd/certs.d"
# # 配置 Dockerhub 国内镜像加速地址
# containerd_registries:
#   "docker.io": "https://registry-1.docker.io"
# containerd_extra_args: ""

# # 国内镜像加速(若不需要加速，请将值删去，键保留)
# docker_mirror: 
# - "https://reg-mirror.qiniu.com"
# - "https://hub-mirror.c.163.com"
# - "https://docker.mirrors.ustc.edu.cn"

# # 信任的不安全镜像库地址，默认为 Pod 和 Service 网段
# docker_insecure_registries:
# - "{{ kube_pod_subnet }}"
# - "{{ kube_service_subnet }}"

# # docker日志相关
# docker_log_driver: "json-file"
# docker_log_level: "warn"
# docker_log_max_size: "10m"
# docker_log_max_file: 3

# # docker容器存储目录
# docker_storage_dir: "/var/lib/docker"

# # docker 默认网桥网段
# docker_bip: "172.17.0.1/16"

# # 并行镜像下载数量
# docker_max_concurrent_downloads: 10

# # ------------------------ #
# # load-balancer 相关参数配置
# # ------------------------ #
# # 私有云：
# #    VIP 负载模式：
# #       也就是负载均衡器 + keepalived 模式，比如常用的 haproxy + keepalived。
# #       本脚本中负载均衡器有 nginx、openresty、haproxy、envoy 可供选择，设置 lb_mode 即可进行任意切换。
# #       设置 lb_kube_apiserver_ip 即表示启用 keepalived，请先与服务器提供部门协商保留一个IP作为 lb_kube_apiserver_ip，
# #       一般 lb 节点组中有两个节点就够了，lb节点组中第一个节点为 keepalived 的 master 节点，剩下的都为 backed 节点。
# #
# #    节点本地负载模式：
# #       只启动负载均衡器，不启用 keepalived（即不设置 lb_kube_apiserver_ip），
# #       此时 kubelet 链接 apiserver 地址为 127.0.0.1:lb_kube_apiserver_port。
# #       使用此模式时请将 lb 节点组置空。
# #
# # 公有云：
# #    不推荐使用 slb 模式，建议直接使用节点本地负载模式。
# #    若使用 slb 模式，请先使用节点本地负载模式进行部署，
# #    部署成功后再切换至 slb 模式：
# #       将 lb_mode 修改为 slb，将 lb_kube_apiserver_ip 设置为购买到的 slb 内网ip，
# #       修改 lb_kube_apiserver_port 为 slb 监听端口。
# #    再次运行初始化集群脚本即可切换至 slb 模式。
# lb_mode: nginx

# # 使用负载均衡后集群 apiserver ip
# lb_kube_apiserver_ip: "192.168.56.15"

# # 使用负载均衡后集群 apiserver port
# lb_kube_apiserver_port: 8443

# # 负载均衡器健康检查端口
# lb_kube_apiserver_healthcheck_port: 8081

# # 启用 ingress NodePort服务的负载均衡 (true/false)
# enabel_ingress_nodeport_lb: false
# # 启用 ingress tls NodePort服务的负载均衡 (true/false)
# enabel_ingress_tls_nodeport_lb: false

# # kubernetes各组件镜像仓库前缀
# kube_image_repository: registry.aliyuncs.com/kubeadm-ha

# # 使用openresty进行apiserver负载时使用的openresty镜像
# lb_openresty_image: "{{ kube_image_repository }}/openresty_openresty:1.19.3.1-alpine"

# # 使用nginx进行apiserver负载时使用的nginx镜像
# lb_nginx_image: "{{ kube_image_repository }}/nginx:1.23-alpine"

# # 使用haproxy进行apiserver负载时使用的haproxy镜像
# lb_haproxy_image: "{{ kube_image_repository }}/haproxy:2.3-alpine"
# # haproxy监控绑定端口
# lb_haproxy_stats_bind_address: 9090
# # haproxy监控访问路径
# lb_haproxy_stats_uri: "/stats"
# # haproxy监控自动刷新时间（秒）
# lb_haproxy_stats_refresh: 10
# # haproxy监控用户名
# lb_haproxy_stats_user: "admin"
# # haproxy监控用户密码
# lb_haproxy_stats_password: "admin"
# # haproxy负载均衡算法，常见如下：
# # "roundrobin": 基于服务器权重的轮询
# # "leastconn": 基于服务器最小连接数
# # "source": 基于请求源IP地址
# # "uri": 基于请求的URI
# lb_haproxy_balance_alg: "leastconn"

# # 使用haproxy进行apiserver负载时使用的haproxy镜像
# lb_envoy_image: "{{ kube_image_repository }}/envoyproxy_envoy:v1.16.2"
# lb_envoy_admin_address_port: 9090

# # 使用 vip 负载时使用的 keepalived 镜像
# lb_keepalived_image: "{{ kube_image_repository }}/osixia_keepalived:2.0.20"
# # keepalived auth_type 的 password
# lb_keepalived_password: "d0cker"
# # 区分多个 instance 的 VRRP 组播，同网段不能重复，取值在0-255之间
# lb_keepalived_router_id: 51

# # ------------------------ #
# # Etcd 相关参数配置
# # ------------------------ #

# # Etcd证书过期时间（天）
# etcd_certs_expired: 3650
# # Etcd根证书过期时间（天）
# etcd_ca_certs_expired: 36500
# # Etcd使用的镜像
# etcd_image: "{{ kube_image_repository }}/etcd:3.5.7-0"
# # Etcd 数据根目录
# etcd_data_dir: "/var/lib/etcd"
# # Etcd 每日备份时间，默认3，即凌晨3点，取值范围0-23
# etcd_backup_hour: "3"
# # Etcd 每日备份文件保留时长，默认7天
# etcd_backup_expiry: "7"

# # ------------------------ #
# # kubernetes 相关参数配置
# # ------------------------ #

# # kubernetes证书过期时间（天）
# kube_certs_expired: 3650
# # kubernetes根证书过期时间（天）
# kube_ca_certs_expired: 36500

# # 加入集群token
# kubeadm_token: "abcdef.0123456789abcdef"

# # k8s 集群 master 节点证书配置，可以添加多个ip和域名（比如增加公网ip和域名）
# kube_master_external_ip:
# - "8.8.8.8"
# kube_master_external_domain:
# - "kubernetes.io"

# # Pod根容器
# pod_infra_container_image: "{{ kube_image_repository }}/pause:3.9"

# # kubernetes版本
# kube_version: 1.27.4
# kube_cni_version: 1.2.0

# # 集群内部dns域名
# kube_dns_domain: cluster.local

# # 网段选择：pod 和 service 的网段不能与服务器网段重叠，
# # 若有重叠请配置 `kube_pod_subnet` 和 `kube_service_subnet` 变量设置 pod 和 service 的网段，示例参考：
# #    如果服务器网段为：10.0.0.1/8
# #       pod 网段可设置为：192.168.0.0/18
# #       service 网段可设置为 192.168.64.0/18
# #    如果服务器网段为：172.16.0.1/12
# #       pod 网段可设置为：10.244.0.0/18
# #       service 网段可设置为 10.244.64.0/18
# #    如果服务器网段为：192.168.0.1/16
# #       pod 网段可设置为：10.244.0.0/18
# #       service 网段可设置为 10.244.64.0/18
# # 集群pod ip段，默认掩码位 18 即 16384 个ip
# kube_pod_subnet: 10.244.0.0/18
# # 集群service ip段
# kube_service_subnet: 10.244.64.0/18
# # 分配给节点的 pod 子网掩码位，默认为 24 即 256 个ip，故使用这些默认值可以纳管 16384/256=64 个节点。
# kube_network_node_prefix: 24

# # node节点最大 pod 数。数量与分配给节点的 pod 子网有关，ip 数应大于 pod 数。
# # https://cloud.google.com/kubernetes-engine/docs/how-to/flexible-pod-cidr
# kube_max_pods: 110

# # NodePort端口范围
# kube_service_node_port_range: 30000-32767

# # 资源保留相关配置
# eviction_hard_imagefs_available: 15%
# eviction_hard_memory_available: 100Mi
# eviction_hard_nodefs_available: 10%
# eviction_hard_nodefs_inodes_free: 5%

# # kubernetes组件预留资源
# kube_cpu_reserved: 100m
# kube_memory_reserved: 256M
# kube_ephemeral_storage_reserved: 1G

# # 操作系统守护进程预留资源
# system_reserved_enabled: true
# # 取消注释以覆盖默认值
# system_cpu_reserved: 500m
# system_memory_reserved: 512M
# system_ephemeral_storage_reserved: 10G

# # 默认使用kube-proxy的 'iptables' 模式，可选 'ipvs' 模式
# kube_proxy_mode: iptables

# # Kubelet 根目录
# kubelet_root_dir: "/var/lib/kubelet"

# ## 存入 Etcd 时的 Secret 进行静态加密 
# # 仅支持: aescbc, secretbox 或 aesgcm
# kube_encryption_algorithm: "aescbc"
# # 将Secret数据加密存储到etcd中的配置文件，下面加密码由 head -c 32 /dev/urandom | base64 生成
# kube_encrypt_token: "GPG4RC0Vyk7+Mz/niQPttxLIeL4HF96oRCcBRyKNpfM="

# ## 审计相关配置
# # 是否启用审计
# kubernetes_audit: false
# # 保留审计日志最大天数
# audit_log_maxage: 30
# # 保留审计日志最大个数
# audit_log_maxbackups: 10
# # 保留审计日志最大容量（MB）
# audit_log_maxsize: 100
# # 审计日志文件挂载在主机上的目录
# audit_log_hostpath: /var/log/kubernetes/audit
# # 审计策略配置文件路径
# audit_policy_file: /etc/kubernetes/config/apiserver-audit-policy.yaml
# # 自定义审计日志规则 (替换默认的审计规则)
# audit_policy_custom_rules: |
#   - level: None
#     users: []
#     verbs: []
#     resources: []

# # 1.10+ admission plugins
# kube_apiserver_enable_admission_plugins: 
# - NodeRestriction
# # - AlwaysPullImages

# # 1.10+ list of disabled admission plugins
# kube_apiserver_disable_admission_plugins: []

# # kube-controller-manager 标记 kubelet(node) 为不健康的周期
# kube_controller_node_monitor_grace_period: 40s
# # kube-controller-manager 定期检查 kubelet(node) 状态周期
# kube_controller_node_monitor_period: 5s
# # exit 状态的 pod 超过多少会触发 gc，默认值 12500，这里改为了 10
# kube_controller_terminated_pod_gc_threshold: 10

# ## Extra args for k8s components passing by kubeadm
# ## example：
# kube_kubeadm_apiserver_extra_args:
#   runtime-config: api/all=true
# kube_kubeadm_apiserver_extra_args: {}
# kube_kubeadm_controller_extra_args: {}
# kube_kubeadm_scheduler_extra_args: {}

# ## Extra control plane host volume mounts
# ## Example:
# apiserver_extra_volumes:
#  - name: name
#    hostPath: /host/path
#    mountPath: /mount/path
#    readOnly: true
# apiserver_extra_volumes: {}
# controller_manager_extra_volumes: {}
# scheduler_extra_volumes: {}

# # ------------------------ #
# # 集群插件相关参数配置
# # ------------------------ #

# # 是否等待插件运行成功
# wait_plugins_ready: true

# # ------------------------ #
# # 集群网络插件相关参数配置
# # ------------------------ #

# # 是否启用网络组建
# network_plugins_enabled: true

# # 集群网络插件，目前支持flannel, calico
# network_plugin: "calico"

# # 设置calico 网络 backend: brid, vxlan, none
# calico_backend: bird
# # calico mtu
# calico_veth_mtu: 0
# # calico 相关镜像
# calico_typha_image: "{{ kube_image_repository }}/calico_typha:v3.26.1"
# calico_cni_image: "{{ kube_image_repository }}/calico_cni:v3.26.1"
# calico_node_image: "{{ kube_image_repository }}/calico_node:v3.26.1"
# calico_kube_controllers_image: "{{ kube_image_repository }}/calico_kube-controllers:v3.26.1"
# # 设置 Felix 日志级别(debug, info, warning, error)
# calico_felix_log_level: "warning"
# # calicoctl image 地址
# calicoctl_image: "{{ kube_image_repository }}/calico_ctl:v3.26.1"

# # 设置 flannel 后端
# # flannel_backend: "host-gw"
# flannel_backend: "vxlan"
# # flannel 镜像地址
# flannel_image: "{{ kube_image_repository }}/flannel_flannel:v0.22.1"
# flannel_cni_plugin_image: "{{ kube_image_repository }}/flannel_flannel-cni-plugin:v1.2.0"

# # ------------------------ #
# # ingress-controller 相关参数配置
# # ------------------------ #

# # 是否启用ingress-controller
# ingress_controller_enabled: true

# # ingress-controller类型(nginx,traefik)
# ingress_controller_tpye: nginx

# # nginx-ingress-controller 镜像地址
# nginx_ingress_image: "{{ kube_image_repository }}/ingress-nginx_controller:v1.8.1"
# nginx_ingress_webhook_certgen_image: "{{ kube_image_repository }}/ingress-nginx_kube-webhook-certgen:v20230407"

# # traefik默认证书过期时间（天）
# traefik_certs_expired: 3650
# # traefik-ingress-controller 镜像地址
# traefik_ingress_image: "{{ kube_image_repository }}/traefik:v2.10.4"

# # ------------------------ #
# # kubernetes-dashboard 相关参数配置
# # ------------------------ #

# # 是否启用kubernetes-dashboard 
# kubernetesui_dashboard_enabled: false

# # kubernetes-dashboard默认证书有效期
# kubernetesui_dashboard_certs_expired: 3650

# # kubernetes-dashboard 镜像地址
# kubernetesui_dashboard_image: "{{ kube_image_repository }}/kubernetesui_dashboard:v2.7.0"
# kubernetesui_metrics_scraper_image: "{{ kube_image_repository }}/kubernetesui_metrics-scraper:v1.0.8"

# # ------------------------ #
# # metrics-server 相关参数配置 
# # ------------------------ #

# # 是否启用metrics-server
# metrics_server_enabled: true

# # metrics-server image地址
# metrics_server_image: "{{ kube_image_repository }}/metrics-server_metrics-server:v0.6.4"

# # ------------------------ #
# # cert-manager 相关配置
# # ------------------------ #

# # 是否启用cert-manager
# cert_manager_enabled: false

# # acme相关配置
# acme_email: yourname@gmail.com
# acme_server: https://acme-v02.api.letsencrypt.org/directory

# # cert-manager 相关 image 地址
# cert_manager_cainjector_image: "{{ kube_image_repository }}/jetstack_cert-manager-cainjector:v1.12.3"
# cert_manager_webhook_image: "{{ kube_image_repository }}/jetstack_cert-manager-webhook:v1.12.3"
# cert_manager_controller_image: "{{ kube_image_repository }}/jetstack_cert-manager-controller:v1.12.3"
# cert_manager_acmesolver_image: "{{ kube_image_repository }}/jetstack_cert-manager-acmesolver::v1.12.3"
